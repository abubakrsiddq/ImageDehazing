{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "modelSub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakrsiddq/ImageDehazing/blob/main/models/FFA-net/ffa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "264bd93a-379d-49ee-ba15-c5da156e5c2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    img = tf.image.per_image_standardization(img)\n",
        "    return img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf"
      },
      "source": [
        "def dataset_preposses(orig_path='/content/drive/MyDrive/dataset/clear_images',haze_path='/content/drive/MyDrive/dataset/haze',percentage=0.2,validation_size=64,test_size=64,seed_val=900):\n",
        "  '''\n",
        "  parameters:\n",
        "  orig_path(string): path of ground truth folder\n",
        "  haze_path(string): path of haze folder\n",
        "  percentage(float): percentage of dataset to load\n",
        "  validation_size(int): the no. of validation images\n",
        "  test_size(int): the no. of test images\n",
        "\n",
        "  returns:\n",
        "  haze_list,validation_list,test_list\n",
        "  '''\n",
        "  random.seed(seed_val)\n",
        "  pth=haze_path+'/*.jpg'\n",
        "  haze_path_list = glob.glob(pth)\n",
        "  orig_path_list=glob.glob(orig_path+'/*.jpg')\n",
        "  #print(orig_path_list)\n",
        "  random.shuffle(haze_path_list)\n",
        "  #print(haze_path_list)\n",
        "  haze_path_dict={}\n",
        "  haze_count_dict={}\n",
        "  haze_list=[]\n",
        "  no_per_set=int(percentage*35)\n",
        "  for i in haze_path_list:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    if(int(name)>468):\n",
        "      try:\n",
        "        if(haze_count_dict[name]<no_per_set):\n",
        "          haze_path_dict[name].append(i)\n",
        "          \n",
        "          haze_count_dict[name]+=1;\n",
        "          \n",
        "      except KeyError:\n",
        "       \n",
        "        haze_path_dict[name]=[]\n",
        "        haze_path_dict[name].append(i)\n",
        "        haze_count_dict[name]=1\n",
        "    #print(haze_path_dict)\n",
        "  test_list=haze_path_list[-1*test_size:]\n",
        "  val_list=haze_path_list[-1*(validation_size+test_size):-1*test_size];\n",
        "\n",
        "  for (key,val) in haze_path_dict.items():\n",
        "    for i in val:\n",
        "      haze_list.append(i)\n",
        "  return haze_list,val_list,test_list\n",
        "\n",
        "\n",
        "def gen_dataset(ar):\n",
        "  '''\n",
        "  parameters\n",
        "  list of paths\n",
        "  return\n",
        "  list with gt attached \n",
        "  '''\n",
        "  orig_path='/content/drive/MyDrive/dataset/clear_images'\n",
        "  haze_pth='/content/drive/MyDrive/dataset/haze'\n",
        "  lst=[]\n",
        "  for i in ar:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    pthlist=[i,orig_path+'/'+name+'.jpg']\n",
        "    lst.append(pthlist)\n",
        "  return lst\n",
        "\n",
        "def data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze'):\n",
        "  \n",
        "  (a,b,c)=dataset_preposses(orig_path=orig_img_path,haze_path=hazy_img_path)\n",
        "  a=gen_dataset(a)\n",
        "  b=gen_dataset(b)\n",
        "  return a,b"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    print(len(train_data))\n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "import cv2\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    #print(\"input image quality\",display_list)#niqe(cv2.imread(display_list[1])))\n",
        "    #print(\"input image quality\",niqe(cv2.imread(display_list[2])))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsyBHZ12mMQ1"
      },
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True,activation='relu'):\n",
        "    return tf.keras.layers.Conv2D(out_channels, kernel_size,padding='same', use_bias=bias,activation=activation)\n",
        "    \n",
        "class PixAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(PixAtLayer, self).__init__()\n",
        "        self.pa = tf.keras.Sequential()\n",
        "        self.pa.add(tf.keras.layers.Conv2D(channel // 8, 1, padding='valid',activation='relu'))\n",
        "        self.pa.add(tf.keras.layers.Conv2D( 1, 1,activation='sigmoid'))\n",
        "    def call(self, x):\n",
        "        y = self.pa(x)\n",
        "        #return y\n",
        "        return x * y\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (352, 1216, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "class adapavgpooling(tf.keras.Model):\n",
        "  def __init__(self,outputsize):\n",
        "    super(adapavgpooling,self).__init__()\n",
        "    self.outputsize=outputsize\n",
        "\n",
        "  def call(self,x):\n",
        "    x_shape=tf.keras.backend.int_shape(x)\n",
        "    batchsize1,dim1,dim2,channels1=x_shape\n",
        "    stride=np.floor(dim2/self.outputsize).astype(np.int32)\n",
        "    kernels=dim1-(self.outputsize-1)*stride\n",
        "    adpooling=tf.keras.layers.AveragePooling2D(pool_size=(kernels,kernels),strides=(stride,stride))(x)\n",
        "    return adpooling\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (352, 1216, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "'''    \n",
        "def adapavgpooling(x,outsize):\n",
        "    x_shape=tf.keras.backend.int_shape(x)\n",
        "    batchsize1,dim1,dim2,channels1=x_shape\n",
        "    stride=np.floor(dim1/outsize).astype(np.int32)\n",
        "    kernels=dim1-(outsize-1)*stride\n",
        "    adpooling=tf.keras.layers.AveragePooling2D(pool_size=(kernels,kernels),strides=(stride,stride))(x)\n",
        "    \n",
        "    return adpooling\n",
        "'''\n",
        "class ChanAtLayer(tf.keras.Model):\n",
        "  def __init__(self, channel):\n",
        "      super(ChanAtLayer, self).__init__()\n",
        "      #self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "      self.ca = tf.keras.Sequential()\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel // 8, 1,activation='relu'))\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel, 1, activation='sigmoid'))\n",
        "      self.adPool=adapavgpooling(1)\n",
        "  def call(self, x):\n",
        "      y = self.adPool(x)\n",
        "      #print(y.shape)\n",
        "      y = self.ca(y)\n",
        "      \n",
        "      return x * y\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (352, 1216, 64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcin-mNmRwv"
      },
      "source": [
        "#sub = PixAtLayer(64)\n",
        "#sub.model().summary()\n",
        "#sub1 = ChanAtLayer(64)\n",
        "#sub1.model().summary()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW2s_Zopmb3q"
      },
      "source": [
        "class Block_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block_layer, self).__init__()\n",
        "        self.conv1=conv(dim,dim, kernel_size, bias=True,activation='relu')\n",
        "        \n",
        "        self.conv2=conv(dim,dim, kernel_size, bias=True)\n",
        "        self.calayer=ChanAtLayer(dim)\n",
        "        self.palayer=PixAtLayer(dim)\n",
        "    def call(self, x):\n",
        "        res=self.conv1(x)\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (352, 1216, 64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzP1jFwLmfr3"
      },
      "source": [
        "#sub1 =Block_layer(default_conv,64,3)\n",
        "#sub1.model().summary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOzDIDpqjZBn"
      },
      "source": [
        "class Group_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group_layer, self).__init__()\n",
        "        modules = [ Block_layer(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(tf.keras.layers.Conv2D(dim, kernel_size,padding='same'))\n",
        "        self.gp = tf.keras.Sequential()\n",
        "        for lay in modules:\n",
        "          self.gp.add(lay)\n",
        "        \n",
        "    def call(self,input_tensor):\n",
        "        res = self.gp(input_tensor)\n",
        "        #res =tf.keras.layers.Add()([res,input_tensor])\n",
        "        res+=input_tensor\n",
        "        return res\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (352, 1216, 64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IypzZI1tnZ2X"
      },
      "source": [
        "#sub1 =Group_layer(default_conv,64,3,6)\n",
        "#sub1.model().summary()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCX-CqzehI3"
      },
      "source": [
        "class FFAnet(tf.keras.Model):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFAnet, self).__init__()\n",
        "        # define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [tf.keras.layers.Conv2D(self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        l=[\n",
        "            adapavgpooling(1),\n",
        "            tf.keras.layers.Conv2D(self.dim//16,1,padding='valid'),\n",
        "            \n",
        "            tf.keras.layers.Conv2D(self.dim*self.gps, 1, padding='valid', use_bias=True,activation='sigmoid')\n",
        "            \n",
        "            ]\n",
        "       \n",
        "        self.ca=tf.keras.Sequential()\n",
        "        for lay in l:\n",
        "          self.ca.add(lay)\n",
        "        self.palayer=PixAtLayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = tf.keras.Sequential(conv(3,self.dim, kernel_size),name='preprocess')\n",
        "\n",
        "        self.post = tf.keras.Sequential(name='postprocess')\n",
        "        for lay in post_precess:\n",
        "          self.post.add(lay)\n",
        "        \n",
        "    def call(self, input_tensor = (None,None, 3), training=False):\n",
        "        #input_tensor=tf.keras.layers.InputLayer(input_shape=(352,1216,3))(input_tensor)\n",
        "        # forward pass: block 1 \n",
        "        input_tensor=tf.keras.layers.experimental.preprocessing.Normalization(axis=-1,mean=[0.485, 0.456, 0.406], variance=[0.229**2, 0.224**2, 0.225**2])(input_tensor)#self.norm(input_tensor)\n",
        "        x = self.pre(input_tensor)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "\n",
        "        #return res3\n",
        "        w=self.ca(tf.keras.layers.concatenate([res1,res2,res3],axis=-1))\n",
        "        w=tf.keras.layers.Reshape((1,self.gps,self.dim))(w)\n",
        "        out=w[:,:,0]*res1+w[:,:,1]*res2+w[:,:,2]*res3\n",
        "        out=self.palayer(out)\n",
        "        x=self.post(out)\n",
        "        return x + input_tensor\n",
        "        #return out\n",
        "       \n",
        "    def model(self):\n",
        "        x = Input(shape = (352, 1216, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "    def build_graph(self):\n",
        "        x = Input(shape=(352, 1216, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htg4Y_MW0Jfo",
        "outputId": "11786301-a190-4c74-f8fb-67089f8ddf46"
      },
      "source": [
        "model=FFAnet(gps=3,blocks=19)\n",
        "model.model().summary()\n",
        "dot_img_file = '/tmp/model_1.png'\n",
        "tf.keras.utils.plot_model(\n",
        "    model.build_graph(),                      # here is the trick (for now)\n",
        "    to_file='model.png', dpi=96,              # saving  \n",
        "    show_shapes=True, show_layer_names=True,  # show shapes and layer name\n",
        "    expand_nested=False                       # will show nested block\n",
        ")\n",
        "model.load_weights('/content/drive/MyDrive/nets/ffa/weights')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 352, 1216, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "normalization (Normalization)   (None, 352, 1216, 3) 7           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "preprocess (Sequential)         (None, 352, 1216, 64 1792        normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "group_layer (Group_layer)       (None, 352, 1216, 64 1471067     preprocess[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "group_layer_1 (Group_layer)     (None, 352, 1216, 64 1471067     group_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "group_layer_2 (Group_layer)     (None, 352, 1216, 64 1471067     group_layer_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 352, 1216, 19 0           group_layer[0][0]                \n",
            "                                                                 group_layer_1[0][0]              \n",
            "                                                                 group_layer_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_117 (Sequential)     (None, 1, 1, 192)    1732        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 3, 64)     0           sequential_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 1, 64)        0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 1, 64)        0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply (TFOpLambda)   (None, 352, 1216, 64 0           tf.__operators__.getitem[0][0]   \n",
            "                                                                 group_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_1 (TFOpLambda) (None, 352, 1216, 64 0           tf.__operators__.getitem_1[0][0] \n",
            "                                                                 group_layer_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 1, 64)        0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 352, 1216, 64 0           tf.math.multiply[0][0]           \n",
            "                                                                 tf.math.multiply_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_2 (TFOpLambda) (None, 352, 1216, 64 0           tf.__operators__.getitem_2[0][0] \n",
            "                                                                 group_layer_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 352, 1216, 64 0           tf.__operators__.add[0][0]       \n",
            "                                                                 tf.math.multiply_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "pix_at_layer_57 (PixAtLayer)    (None, 352, 1216, 64 529         tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "postprocess (Sequential)        (None, 352, 1216, 3) 38659       pix_at_layer_57[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 352, 1216, 3) 0           postprocess[0][0]                \n",
            "                                                                 normalization[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,455,920\n",
            "Trainable params: 4,455,913\n",
            "Non-trainable params: 7\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fafce9a5390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcicUdgRwynb"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blcQ-2_cwMNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052f5b2d-7c8c-48c8-e0f2-a9f64f883333"
      },
      "source": [
        "import torch\n",
        "pretrain=torch.load('/content/drive/MyDrive/ots_train_ffa_3_19.pk',map_location=torch.device('cpu'))\n",
        "pretrain.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['step', 'max_psnr', 'max_ssim', 'ssims', 'psnrs', 'losses', 'model'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEIMusj9wMWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a68962-fe94-45d9-a8dd-e77dc8649ae1"
      },
      "source": [
        "pretrain['model'].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['module.g1.gp.0.conv1.weight', 'module.g1.gp.0.conv1.bias', 'module.g1.gp.0.conv2.weight', 'module.g1.gp.0.conv2.bias', 'module.g1.gp.0.calayer.ca.0.weight', 'module.g1.gp.0.calayer.ca.0.bias', 'module.g1.gp.0.calayer.ca.2.weight', 'module.g1.gp.0.calayer.ca.2.bias', 'module.g1.gp.0.palayer.pa.0.weight', 'module.g1.gp.0.palayer.pa.0.bias', 'module.g1.gp.0.palayer.pa.2.weight', 'module.g1.gp.0.palayer.pa.2.bias', 'module.g1.gp.1.conv1.weight', 'module.g1.gp.1.conv1.bias', 'module.g1.gp.1.conv2.weight', 'module.g1.gp.1.conv2.bias', 'module.g1.gp.1.calayer.ca.0.weight', 'module.g1.gp.1.calayer.ca.0.bias', 'module.g1.gp.1.calayer.ca.2.weight', 'module.g1.gp.1.calayer.ca.2.bias', 'module.g1.gp.1.palayer.pa.0.weight', 'module.g1.gp.1.palayer.pa.0.bias', 'module.g1.gp.1.palayer.pa.2.weight', 'module.g1.gp.1.palayer.pa.2.bias', 'module.g1.gp.2.conv1.weight', 'module.g1.gp.2.conv1.bias', 'module.g1.gp.2.conv2.weight', 'module.g1.gp.2.conv2.bias', 'module.g1.gp.2.calayer.ca.0.weight', 'module.g1.gp.2.calayer.ca.0.bias', 'module.g1.gp.2.calayer.ca.2.weight', 'module.g1.gp.2.calayer.ca.2.bias', 'module.g1.gp.2.palayer.pa.0.weight', 'module.g1.gp.2.palayer.pa.0.bias', 'module.g1.gp.2.palayer.pa.2.weight', 'module.g1.gp.2.palayer.pa.2.bias', 'module.g1.gp.3.conv1.weight', 'module.g1.gp.3.conv1.bias', 'module.g1.gp.3.conv2.weight', 'module.g1.gp.3.conv2.bias', 'module.g1.gp.3.calayer.ca.0.weight', 'module.g1.gp.3.calayer.ca.0.bias', 'module.g1.gp.3.calayer.ca.2.weight', 'module.g1.gp.3.calayer.ca.2.bias', 'module.g1.gp.3.palayer.pa.0.weight', 'module.g1.gp.3.palayer.pa.0.bias', 'module.g1.gp.3.palayer.pa.2.weight', 'module.g1.gp.3.palayer.pa.2.bias', 'module.g1.gp.4.conv1.weight', 'module.g1.gp.4.conv1.bias', 'module.g1.gp.4.conv2.weight', 'module.g1.gp.4.conv2.bias', 'module.g1.gp.4.calayer.ca.0.weight', 'module.g1.gp.4.calayer.ca.0.bias', 'module.g1.gp.4.calayer.ca.2.weight', 'module.g1.gp.4.calayer.ca.2.bias', 'module.g1.gp.4.palayer.pa.0.weight', 'module.g1.gp.4.palayer.pa.0.bias', 'module.g1.gp.4.palayer.pa.2.weight', 'module.g1.gp.4.palayer.pa.2.bias', 'module.g1.gp.5.conv1.weight', 'module.g1.gp.5.conv1.bias', 'module.g1.gp.5.conv2.weight', 'module.g1.gp.5.conv2.bias', 'module.g1.gp.5.calayer.ca.0.weight', 'module.g1.gp.5.calayer.ca.0.bias', 'module.g1.gp.5.calayer.ca.2.weight', 'module.g1.gp.5.calayer.ca.2.bias', 'module.g1.gp.5.palayer.pa.0.weight', 'module.g1.gp.5.palayer.pa.0.bias', 'module.g1.gp.5.palayer.pa.2.weight', 'module.g1.gp.5.palayer.pa.2.bias', 'module.g1.gp.6.conv1.weight', 'module.g1.gp.6.conv1.bias', 'module.g1.gp.6.conv2.weight', 'module.g1.gp.6.conv2.bias', 'module.g1.gp.6.calayer.ca.0.weight', 'module.g1.gp.6.calayer.ca.0.bias', 'module.g1.gp.6.calayer.ca.2.weight', 'module.g1.gp.6.calayer.ca.2.bias', 'module.g1.gp.6.palayer.pa.0.weight', 'module.g1.gp.6.palayer.pa.0.bias', 'module.g1.gp.6.palayer.pa.2.weight', 'module.g1.gp.6.palayer.pa.2.bias', 'module.g1.gp.7.conv1.weight', 'module.g1.gp.7.conv1.bias', 'module.g1.gp.7.conv2.weight', 'module.g1.gp.7.conv2.bias', 'module.g1.gp.7.calayer.ca.0.weight', 'module.g1.gp.7.calayer.ca.0.bias', 'module.g1.gp.7.calayer.ca.2.weight', 'module.g1.gp.7.calayer.ca.2.bias', 'module.g1.gp.7.palayer.pa.0.weight', 'module.g1.gp.7.palayer.pa.0.bias', 'module.g1.gp.7.palayer.pa.2.weight', 'module.g1.gp.7.palayer.pa.2.bias', 'module.g1.gp.8.conv1.weight', 'module.g1.gp.8.conv1.bias', 'module.g1.gp.8.conv2.weight', 'module.g1.gp.8.conv2.bias', 'module.g1.gp.8.calayer.ca.0.weight', 'module.g1.gp.8.calayer.ca.0.bias', 'module.g1.gp.8.calayer.ca.2.weight', 'module.g1.gp.8.calayer.ca.2.bias', 'module.g1.gp.8.palayer.pa.0.weight', 'module.g1.gp.8.palayer.pa.0.bias', 'module.g1.gp.8.palayer.pa.2.weight', 'module.g1.gp.8.palayer.pa.2.bias', 'module.g1.gp.9.conv1.weight', 'module.g1.gp.9.conv1.bias', 'module.g1.gp.9.conv2.weight', 'module.g1.gp.9.conv2.bias', 'module.g1.gp.9.calayer.ca.0.weight', 'module.g1.gp.9.calayer.ca.0.bias', 'module.g1.gp.9.calayer.ca.2.weight', 'module.g1.gp.9.calayer.ca.2.bias', 'module.g1.gp.9.palayer.pa.0.weight', 'module.g1.gp.9.palayer.pa.0.bias', 'module.g1.gp.9.palayer.pa.2.weight', 'module.g1.gp.9.palayer.pa.2.bias', 'module.g1.gp.10.conv1.weight', 'module.g1.gp.10.conv1.bias', 'module.g1.gp.10.conv2.weight', 'module.g1.gp.10.conv2.bias', 'module.g1.gp.10.calayer.ca.0.weight', 'module.g1.gp.10.calayer.ca.0.bias', 'module.g1.gp.10.calayer.ca.2.weight', 'module.g1.gp.10.calayer.ca.2.bias', 'module.g1.gp.10.palayer.pa.0.weight', 'module.g1.gp.10.palayer.pa.0.bias', 'module.g1.gp.10.palayer.pa.2.weight', 'module.g1.gp.10.palayer.pa.2.bias', 'module.g1.gp.11.conv1.weight', 'module.g1.gp.11.conv1.bias', 'module.g1.gp.11.conv2.weight', 'module.g1.gp.11.conv2.bias', 'module.g1.gp.11.calayer.ca.0.weight', 'module.g1.gp.11.calayer.ca.0.bias', 'module.g1.gp.11.calayer.ca.2.weight', 'module.g1.gp.11.calayer.ca.2.bias', 'module.g1.gp.11.palayer.pa.0.weight', 'module.g1.gp.11.palayer.pa.0.bias', 'module.g1.gp.11.palayer.pa.2.weight', 'module.g1.gp.11.palayer.pa.2.bias', 'module.g1.gp.12.conv1.weight', 'module.g1.gp.12.conv1.bias', 'module.g1.gp.12.conv2.weight', 'module.g1.gp.12.conv2.bias', 'module.g1.gp.12.calayer.ca.0.weight', 'module.g1.gp.12.calayer.ca.0.bias', 'module.g1.gp.12.calayer.ca.2.weight', 'module.g1.gp.12.calayer.ca.2.bias', 'module.g1.gp.12.palayer.pa.0.weight', 'module.g1.gp.12.palayer.pa.0.bias', 'module.g1.gp.12.palayer.pa.2.weight', 'module.g1.gp.12.palayer.pa.2.bias', 'module.g1.gp.13.conv1.weight', 'module.g1.gp.13.conv1.bias', 'module.g1.gp.13.conv2.weight', 'module.g1.gp.13.conv2.bias', 'module.g1.gp.13.calayer.ca.0.weight', 'module.g1.gp.13.calayer.ca.0.bias', 'module.g1.gp.13.calayer.ca.2.weight', 'module.g1.gp.13.calayer.ca.2.bias', 'module.g1.gp.13.palayer.pa.0.weight', 'module.g1.gp.13.palayer.pa.0.bias', 'module.g1.gp.13.palayer.pa.2.weight', 'module.g1.gp.13.palayer.pa.2.bias', 'module.g1.gp.14.conv1.weight', 'module.g1.gp.14.conv1.bias', 'module.g1.gp.14.conv2.weight', 'module.g1.gp.14.conv2.bias', 'module.g1.gp.14.calayer.ca.0.weight', 'module.g1.gp.14.calayer.ca.0.bias', 'module.g1.gp.14.calayer.ca.2.weight', 'module.g1.gp.14.calayer.ca.2.bias', 'module.g1.gp.14.palayer.pa.0.weight', 'module.g1.gp.14.palayer.pa.0.bias', 'module.g1.gp.14.palayer.pa.2.weight', 'module.g1.gp.14.palayer.pa.2.bias', 'module.g1.gp.15.conv1.weight', 'module.g1.gp.15.conv1.bias', 'module.g1.gp.15.conv2.weight', 'module.g1.gp.15.conv2.bias', 'module.g1.gp.15.calayer.ca.0.weight', 'module.g1.gp.15.calayer.ca.0.bias', 'module.g1.gp.15.calayer.ca.2.weight', 'module.g1.gp.15.calayer.ca.2.bias', 'module.g1.gp.15.palayer.pa.0.weight', 'module.g1.gp.15.palayer.pa.0.bias', 'module.g1.gp.15.palayer.pa.2.weight', 'module.g1.gp.15.palayer.pa.2.bias', 'module.g1.gp.16.conv1.weight', 'module.g1.gp.16.conv1.bias', 'module.g1.gp.16.conv2.weight', 'module.g1.gp.16.conv2.bias', 'module.g1.gp.16.calayer.ca.0.weight', 'module.g1.gp.16.calayer.ca.0.bias', 'module.g1.gp.16.calayer.ca.2.weight', 'module.g1.gp.16.calayer.ca.2.bias', 'module.g1.gp.16.palayer.pa.0.weight', 'module.g1.gp.16.palayer.pa.0.bias', 'module.g1.gp.16.palayer.pa.2.weight', 'module.g1.gp.16.palayer.pa.2.bias', 'module.g1.gp.17.conv1.weight', 'module.g1.gp.17.conv1.bias', 'module.g1.gp.17.conv2.weight', 'module.g1.gp.17.conv2.bias', 'module.g1.gp.17.calayer.ca.0.weight', 'module.g1.gp.17.calayer.ca.0.bias', 'module.g1.gp.17.calayer.ca.2.weight', 'module.g1.gp.17.calayer.ca.2.bias', 'module.g1.gp.17.palayer.pa.0.weight', 'module.g1.gp.17.palayer.pa.0.bias', 'module.g1.gp.17.palayer.pa.2.weight', 'module.g1.gp.17.palayer.pa.2.bias', 'module.g1.gp.18.conv1.weight', 'module.g1.gp.18.conv1.bias', 'module.g1.gp.18.conv2.weight', 'module.g1.gp.18.conv2.bias', 'module.g1.gp.18.calayer.ca.0.weight', 'module.g1.gp.18.calayer.ca.0.bias', 'module.g1.gp.18.calayer.ca.2.weight', 'module.g1.gp.18.calayer.ca.2.bias', 'module.g1.gp.18.palayer.pa.0.weight', 'module.g1.gp.18.palayer.pa.0.bias', 'module.g1.gp.18.palayer.pa.2.weight', 'module.g1.gp.18.palayer.pa.2.bias', 'module.g1.gp.19.weight', 'module.g1.gp.19.bias', 'module.g2.gp.0.conv1.weight', 'module.g2.gp.0.conv1.bias', 'module.g2.gp.0.conv2.weight', 'module.g2.gp.0.conv2.bias', 'module.g2.gp.0.calayer.ca.0.weight', 'module.g2.gp.0.calayer.ca.0.bias', 'module.g2.gp.0.calayer.ca.2.weight', 'module.g2.gp.0.calayer.ca.2.bias', 'module.g2.gp.0.palayer.pa.0.weight', 'module.g2.gp.0.palayer.pa.0.bias', 'module.g2.gp.0.palayer.pa.2.weight', 'module.g2.gp.0.palayer.pa.2.bias', 'module.g2.gp.1.conv1.weight', 'module.g2.gp.1.conv1.bias', 'module.g2.gp.1.conv2.weight', 'module.g2.gp.1.conv2.bias', 'module.g2.gp.1.calayer.ca.0.weight', 'module.g2.gp.1.calayer.ca.0.bias', 'module.g2.gp.1.calayer.ca.2.weight', 'module.g2.gp.1.calayer.ca.2.bias', 'module.g2.gp.1.palayer.pa.0.weight', 'module.g2.gp.1.palayer.pa.0.bias', 'module.g2.gp.1.palayer.pa.2.weight', 'module.g2.gp.1.palayer.pa.2.bias', 'module.g2.gp.2.conv1.weight', 'module.g2.gp.2.conv1.bias', 'module.g2.gp.2.conv2.weight', 'module.g2.gp.2.conv2.bias', 'module.g2.gp.2.calayer.ca.0.weight', 'module.g2.gp.2.calayer.ca.0.bias', 'module.g2.gp.2.calayer.ca.2.weight', 'module.g2.gp.2.calayer.ca.2.bias', 'module.g2.gp.2.palayer.pa.0.weight', 'module.g2.gp.2.palayer.pa.0.bias', 'module.g2.gp.2.palayer.pa.2.weight', 'module.g2.gp.2.palayer.pa.2.bias', 'module.g2.gp.3.conv1.weight', 'module.g2.gp.3.conv1.bias', 'module.g2.gp.3.conv2.weight', 'module.g2.gp.3.conv2.bias', 'module.g2.gp.3.calayer.ca.0.weight', 'module.g2.gp.3.calayer.ca.0.bias', 'module.g2.gp.3.calayer.ca.2.weight', 'module.g2.gp.3.calayer.ca.2.bias', 'module.g2.gp.3.palayer.pa.0.weight', 'module.g2.gp.3.palayer.pa.0.bias', 'module.g2.gp.3.palayer.pa.2.weight', 'module.g2.gp.3.palayer.pa.2.bias', 'module.g2.gp.4.conv1.weight', 'module.g2.gp.4.conv1.bias', 'module.g2.gp.4.conv2.weight', 'module.g2.gp.4.conv2.bias', 'module.g2.gp.4.calayer.ca.0.weight', 'module.g2.gp.4.calayer.ca.0.bias', 'module.g2.gp.4.calayer.ca.2.weight', 'module.g2.gp.4.calayer.ca.2.bias', 'module.g2.gp.4.palayer.pa.0.weight', 'module.g2.gp.4.palayer.pa.0.bias', 'module.g2.gp.4.palayer.pa.2.weight', 'module.g2.gp.4.palayer.pa.2.bias', 'module.g2.gp.5.conv1.weight', 'module.g2.gp.5.conv1.bias', 'module.g2.gp.5.conv2.weight', 'module.g2.gp.5.conv2.bias', 'module.g2.gp.5.calayer.ca.0.weight', 'module.g2.gp.5.calayer.ca.0.bias', 'module.g2.gp.5.calayer.ca.2.weight', 'module.g2.gp.5.calayer.ca.2.bias', 'module.g2.gp.5.palayer.pa.0.weight', 'module.g2.gp.5.palayer.pa.0.bias', 'module.g2.gp.5.palayer.pa.2.weight', 'module.g2.gp.5.palayer.pa.2.bias', 'module.g2.gp.6.conv1.weight', 'module.g2.gp.6.conv1.bias', 'module.g2.gp.6.conv2.weight', 'module.g2.gp.6.conv2.bias', 'module.g2.gp.6.calayer.ca.0.weight', 'module.g2.gp.6.calayer.ca.0.bias', 'module.g2.gp.6.calayer.ca.2.weight', 'module.g2.gp.6.calayer.ca.2.bias', 'module.g2.gp.6.palayer.pa.0.weight', 'module.g2.gp.6.palayer.pa.0.bias', 'module.g2.gp.6.palayer.pa.2.weight', 'module.g2.gp.6.palayer.pa.2.bias', 'module.g2.gp.7.conv1.weight', 'module.g2.gp.7.conv1.bias', 'module.g2.gp.7.conv2.weight', 'module.g2.gp.7.conv2.bias', 'module.g2.gp.7.calayer.ca.0.weight', 'module.g2.gp.7.calayer.ca.0.bias', 'module.g2.gp.7.calayer.ca.2.weight', 'module.g2.gp.7.calayer.ca.2.bias', 'module.g2.gp.7.palayer.pa.0.weight', 'module.g2.gp.7.palayer.pa.0.bias', 'module.g2.gp.7.palayer.pa.2.weight', 'module.g2.gp.7.palayer.pa.2.bias', 'module.g2.gp.8.conv1.weight', 'module.g2.gp.8.conv1.bias', 'module.g2.gp.8.conv2.weight', 'module.g2.gp.8.conv2.bias', 'module.g2.gp.8.calayer.ca.0.weight', 'module.g2.gp.8.calayer.ca.0.bias', 'module.g2.gp.8.calayer.ca.2.weight', 'module.g2.gp.8.calayer.ca.2.bias', 'module.g2.gp.8.palayer.pa.0.weight', 'module.g2.gp.8.palayer.pa.0.bias', 'module.g2.gp.8.palayer.pa.2.weight', 'module.g2.gp.8.palayer.pa.2.bias', 'module.g2.gp.9.conv1.weight', 'module.g2.gp.9.conv1.bias', 'module.g2.gp.9.conv2.weight', 'module.g2.gp.9.conv2.bias', 'module.g2.gp.9.calayer.ca.0.weight', 'module.g2.gp.9.calayer.ca.0.bias', 'module.g2.gp.9.calayer.ca.2.weight', 'module.g2.gp.9.calayer.ca.2.bias', 'module.g2.gp.9.palayer.pa.0.weight', 'module.g2.gp.9.palayer.pa.0.bias', 'module.g2.gp.9.palayer.pa.2.weight', 'module.g2.gp.9.palayer.pa.2.bias', 'module.g2.gp.10.conv1.weight', 'module.g2.gp.10.conv1.bias', 'module.g2.gp.10.conv2.weight', 'module.g2.gp.10.conv2.bias', 'module.g2.gp.10.calayer.ca.0.weight', 'module.g2.gp.10.calayer.ca.0.bias', 'module.g2.gp.10.calayer.ca.2.weight', 'module.g2.gp.10.calayer.ca.2.bias', 'module.g2.gp.10.palayer.pa.0.weight', 'module.g2.gp.10.palayer.pa.0.bias', 'module.g2.gp.10.palayer.pa.2.weight', 'module.g2.gp.10.palayer.pa.2.bias', 'module.g2.gp.11.conv1.weight', 'module.g2.gp.11.conv1.bias', 'module.g2.gp.11.conv2.weight', 'module.g2.gp.11.conv2.bias', 'module.g2.gp.11.calayer.ca.0.weight', 'module.g2.gp.11.calayer.ca.0.bias', 'module.g2.gp.11.calayer.ca.2.weight', 'module.g2.gp.11.calayer.ca.2.bias', 'module.g2.gp.11.palayer.pa.0.weight', 'module.g2.gp.11.palayer.pa.0.bias', 'module.g2.gp.11.palayer.pa.2.weight', 'module.g2.gp.11.palayer.pa.2.bias', 'module.g2.gp.12.conv1.weight', 'module.g2.gp.12.conv1.bias', 'module.g2.gp.12.conv2.weight', 'module.g2.gp.12.conv2.bias', 'module.g2.gp.12.calayer.ca.0.weight', 'module.g2.gp.12.calayer.ca.0.bias', 'module.g2.gp.12.calayer.ca.2.weight', 'module.g2.gp.12.calayer.ca.2.bias', 'module.g2.gp.12.palayer.pa.0.weight', 'module.g2.gp.12.palayer.pa.0.bias', 'module.g2.gp.12.palayer.pa.2.weight', 'module.g2.gp.12.palayer.pa.2.bias', 'module.g2.gp.13.conv1.weight', 'module.g2.gp.13.conv1.bias', 'module.g2.gp.13.conv2.weight', 'module.g2.gp.13.conv2.bias', 'module.g2.gp.13.calayer.ca.0.weight', 'module.g2.gp.13.calayer.ca.0.bias', 'module.g2.gp.13.calayer.ca.2.weight', 'module.g2.gp.13.calayer.ca.2.bias', 'module.g2.gp.13.palayer.pa.0.weight', 'module.g2.gp.13.palayer.pa.0.bias', 'module.g2.gp.13.palayer.pa.2.weight', 'module.g2.gp.13.palayer.pa.2.bias', 'module.g2.gp.14.conv1.weight', 'module.g2.gp.14.conv1.bias', 'module.g2.gp.14.conv2.weight', 'module.g2.gp.14.conv2.bias', 'module.g2.gp.14.calayer.ca.0.weight', 'module.g2.gp.14.calayer.ca.0.bias', 'module.g2.gp.14.calayer.ca.2.weight', 'module.g2.gp.14.calayer.ca.2.bias', 'module.g2.gp.14.palayer.pa.0.weight', 'module.g2.gp.14.palayer.pa.0.bias', 'module.g2.gp.14.palayer.pa.2.weight', 'module.g2.gp.14.palayer.pa.2.bias', 'module.g2.gp.15.conv1.weight', 'module.g2.gp.15.conv1.bias', 'module.g2.gp.15.conv2.weight', 'module.g2.gp.15.conv2.bias', 'module.g2.gp.15.calayer.ca.0.weight', 'module.g2.gp.15.calayer.ca.0.bias', 'module.g2.gp.15.calayer.ca.2.weight', 'module.g2.gp.15.calayer.ca.2.bias', 'module.g2.gp.15.palayer.pa.0.weight', 'module.g2.gp.15.palayer.pa.0.bias', 'module.g2.gp.15.palayer.pa.2.weight', 'module.g2.gp.15.palayer.pa.2.bias', 'module.g2.gp.16.conv1.weight', 'module.g2.gp.16.conv1.bias', 'module.g2.gp.16.conv2.weight', 'module.g2.gp.16.conv2.bias', 'module.g2.gp.16.calayer.ca.0.weight', 'module.g2.gp.16.calayer.ca.0.bias', 'module.g2.gp.16.calayer.ca.2.weight', 'module.g2.gp.16.calayer.ca.2.bias', 'module.g2.gp.16.palayer.pa.0.weight', 'module.g2.gp.16.palayer.pa.0.bias', 'module.g2.gp.16.palayer.pa.2.weight', 'module.g2.gp.16.palayer.pa.2.bias', 'module.g2.gp.17.conv1.weight', 'module.g2.gp.17.conv1.bias', 'module.g2.gp.17.conv2.weight', 'module.g2.gp.17.conv2.bias', 'module.g2.gp.17.calayer.ca.0.weight', 'module.g2.gp.17.calayer.ca.0.bias', 'module.g2.gp.17.calayer.ca.2.weight', 'module.g2.gp.17.calayer.ca.2.bias', 'module.g2.gp.17.palayer.pa.0.weight', 'module.g2.gp.17.palayer.pa.0.bias', 'module.g2.gp.17.palayer.pa.2.weight', 'module.g2.gp.17.palayer.pa.2.bias', 'module.g2.gp.18.conv1.weight', 'module.g2.gp.18.conv1.bias', 'module.g2.gp.18.conv2.weight', 'module.g2.gp.18.conv2.bias', 'module.g2.gp.18.calayer.ca.0.weight', 'module.g2.gp.18.calayer.ca.0.bias', 'module.g2.gp.18.calayer.ca.2.weight', 'module.g2.gp.18.calayer.ca.2.bias', 'module.g2.gp.18.palayer.pa.0.weight', 'module.g2.gp.18.palayer.pa.0.bias', 'module.g2.gp.18.palayer.pa.2.weight', 'module.g2.gp.18.palayer.pa.2.bias', 'module.g2.gp.19.weight', 'module.g2.gp.19.bias', 'module.g3.gp.0.conv1.weight', 'module.g3.gp.0.conv1.bias', 'module.g3.gp.0.conv2.weight', 'module.g3.gp.0.conv2.bias', 'module.g3.gp.0.calayer.ca.0.weight', 'module.g3.gp.0.calayer.ca.0.bias', 'module.g3.gp.0.calayer.ca.2.weight', 'module.g3.gp.0.calayer.ca.2.bias', 'module.g3.gp.0.palayer.pa.0.weight', 'module.g3.gp.0.palayer.pa.0.bias', 'module.g3.gp.0.palayer.pa.2.weight', 'module.g3.gp.0.palayer.pa.2.bias', 'module.g3.gp.1.conv1.weight', 'module.g3.gp.1.conv1.bias', 'module.g3.gp.1.conv2.weight', 'module.g3.gp.1.conv2.bias', 'module.g3.gp.1.calayer.ca.0.weight', 'module.g3.gp.1.calayer.ca.0.bias', 'module.g3.gp.1.calayer.ca.2.weight', 'module.g3.gp.1.calayer.ca.2.bias', 'module.g3.gp.1.palayer.pa.0.weight', 'module.g3.gp.1.palayer.pa.0.bias', 'module.g3.gp.1.palayer.pa.2.weight', 'module.g3.gp.1.palayer.pa.2.bias', 'module.g3.gp.2.conv1.weight', 'module.g3.gp.2.conv1.bias', 'module.g3.gp.2.conv2.weight', 'module.g3.gp.2.conv2.bias', 'module.g3.gp.2.calayer.ca.0.weight', 'module.g3.gp.2.calayer.ca.0.bias', 'module.g3.gp.2.calayer.ca.2.weight', 'module.g3.gp.2.calayer.ca.2.bias', 'module.g3.gp.2.palayer.pa.0.weight', 'module.g3.gp.2.palayer.pa.0.bias', 'module.g3.gp.2.palayer.pa.2.weight', 'module.g3.gp.2.palayer.pa.2.bias', 'module.g3.gp.3.conv1.weight', 'module.g3.gp.3.conv1.bias', 'module.g3.gp.3.conv2.weight', 'module.g3.gp.3.conv2.bias', 'module.g3.gp.3.calayer.ca.0.weight', 'module.g3.gp.3.calayer.ca.0.bias', 'module.g3.gp.3.calayer.ca.2.weight', 'module.g3.gp.3.calayer.ca.2.bias', 'module.g3.gp.3.palayer.pa.0.weight', 'module.g3.gp.3.palayer.pa.0.bias', 'module.g3.gp.3.palayer.pa.2.weight', 'module.g3.gp.3.palayer.pa.2.bias', 'module.g3.gp.4.conv1.weight', 'module.g3.gp.4.conv1.bias', 'module.g3.gp.4.conv2.weight', 'module.g3.gp.4.conv2.bias', 'module.g3.gp.4.calayer.ca.0.weight', 'module.g3.gp.4.calayer.ca.0.bias', 'module.g3.gp.4.calayer.ca.2.weight', 'module.g3.gp.4.calayer.ca.2.bias', 'module.g3.gp.4.palayer.pa.0.weight', 'module.g3.gp.4.palayer.pa.0.bias', 'module.g3.gp.4.palayer.pa.2.weight', 'module.g3.gp.4.palayer.pa.2.bias', 'module.g3.gp.5.conv1.weight', 'module.g3.gp.5.conv1.bias', 'module.g3.gp.5.conv2.weight', 'module.g3.gp.5.conv2.bias', 'module.g3.gp.5.calayer.ca.0.weight', 'module.g3.gp.5.calayer.ca.0.bias', 'module.g3.gp.5.calayer.ca.2.weight', 'module.g3.gp.5.calayer.ca.2.bias', 'module.g3.gp.5.palayer.pa.0.weight', 'module.g3.gp.5.palayer.pa.0.bias', 'module.g3.gp.5.palayer.pa.2.weight', 'module.g3.gp.5.palayer.pa.2.bias', 'module.g3.gp.6.conv1.weight', 'module.g3.gp.6.conv1.bias', 'module.g3.gp.6.conv2.weight', 'module.g3.gp.6.conv2.bias', 'module.g3.gp.6.calayer.ca.0.weight', 'module.g3.gp.6.calayer.ca.0.bias', 'module.g3.gp.6.calayer.ca.2.weight', 'module.g3.gp.6.calayer.ca.2.bias', 'module.g3.gp.6.palayer.pa.0.weight', 'module.g3.gp.6.palayer.pa.0.bias', 'module.g3.gp.6.palayer.pa.2.weight', 'module.g3.gp.6.palayer.pa.2.bias', 'module.g3.gp.7.conv1.weight', 'module.g3.gp.7.conv1.bias', 'module.g3.gp.7.conv2.weight', 'module.g3.gp.7.conv2.bias', 'module.g3.gp.7.calayer.ca.0.weight', 'module.g3.gp.7.calayer.ca.0.bias', 'module.g3.gp.7.calayer.ca.2.weight', 'module.g3.gp.7.calayer.ca.2.bias', 'module.g3.gp.7.palayer.pa.0.weight', 'module.g3.gp.7.palayer.pa.0.bias', 'module.g3.gp.7.palayer.pa.2.weight', 'module.g3.gp.7.palayer.pa.2.bias', 'module.g3.gp.8.conv1.weight', 'module.g3.gp.8.conv1.bias', 'module.g3.gp.8.conv2.weight', 'module.g3.gp.8.conv2.bias', 'module.g3.gp.8.calayer.ca.0.weight', 'module.g3.gp.8.calayer.ca.0.bias', 'module.g3.gp.8.calayer.ca.2.weight', 'module.g3.gp.8.calayer.ca.2.bias', 'module.g3.gp.8.palayer.pa.0.weight', 'module.g3.gp.8.palayer.pa.0.bias', 'module.g3.gp.8.palayer.pa.2.weight', 'module.g3.gp.8.palayer.pa.2.bias', 'module.g3.gp.9.conv1.weight', 'module.g3.gp.9.conv1.bias', 'module.g3.gp.9.conv2.weight', 'module.g3.gp.9.conv2.bias', 'module.g3.gp.9.calayer.ca.0.weight', 'module.g3.gp.9.calayer.ca.0.bias', 'module.g3.gp.9.calayer.ca.2.weight', 'module.g3.gp.9.calayer.ca.2.bias', 'module.g3.gp.9.palayer.pa.0.weight', 'module.g3.gp.9.palayer.pa.0.bias', 'module.g3.gp.9.palayer.pa.2.weight', 'module.g3.gp.9.palayer.pa.2.bias', 'module.g3.gp.10.conv1.weight', 'module.g3.gp.10.conv1.bias', 'module.g3.gp.10.conv2.weight', 'module.g3.gp.10.conv2.bias', 'module.g3.gp.10.calayer.ca.0.weight', 'module.g3.gp.10.calayer.ca.0.bias', 'module.g3.gp.10.calayer.ca.2.weight', 'module.g3.gp.10.calayer.ca.2.bias', 'module.g3.gp.10.palayer.pa.0.weight', 'module.g3.gp.10.palayer.pa.0.bias', 'module.g3.gp.10.palayer.pa.2.weight', 'module.g3.gp.10.palayer.pa.2.bias', 'module.g3.gp.11.conv1.weight', 'module.g3.gp.11.conv1.bias', 'module.g3.gp.11.conv2.weight', 'module.g3.gp.11.conv2.bias', 'module.g3.gp.11.calayer.ca.0.weight', 'module.g3.gp.11.calayer.ca.0.bias', 'module.g3.gp.11.calayer.ca.2.weight', 'module.g3.gp.11.calayer.ca.2.bias', 'module.g3.gp.11.palayer.pa.0.weight', 'module.g3.gp.11.palayer.pa.0.bias', 'module.g3.gp.11.palayer.pa.2.weight', 'module.g3.gp.11.palayer.pa.2.bias', 'module.g3.gp.12.conv1.weight', 'module.g3.gp.12.conv1.bias', 'module.g3.gp.12.conv2.weight', 'module.g3.gp.12.conv2.bias', 'module.g3.gp.12.calayer.ca.0.weight', 'module.g3.gp.12.calayer.ca.0.bias', 'module.g3.gp.12.calayer.ca.2.weight', 'module.g3.gp.12.calayer.ca.2.bias', 'module.g3.gp.12.palayer.pa.0.weight', 'module.g3.gp.12.palayer.pa.0.bias', 'module.g3.gp.12.palayer.pa.2.weight', 'module.g3.gp.12.palayer.pa.2.bias', 'module.g3.gp.13.conv1.weight', 'module.g3.gp.13.conv1.bias', 'module.g3.gp.13.conv2.weight', 'module.g3.gp.13.conv2.bias', 'module.g3.gp.13.calayer.ca.0.weight', 'module.g3.gp.13.calayer.ca.0.bias', 'module.g3.gp.13.calayer.ca.2.weight', 'module.g3.gp.13.calayer.ca.2.bias', 'module.g3.gp.13.palayer.pa.0.weight', 'module.g3.gp.13.palayer.pa.0.bias', 'module.g3.gp.13.palayer.pa.2.weight', 'module.g3.gp.13.palayer.pa.2.bias', 'module.g3.gp.14.conv1.weight', 'module.g3.gp.14.conv1.bias', 'module.g3.gp.14.conv2.weight', 'module.g3.gp.14.conv2.bias', 'module.g3.gp.14.calayer.ca.0.weight', 'module.g3.gp.14.calayer.ca.0.bias', 'module.g3.gp.14.calayer.ca.2.weight', 'module.g3.gp.14.calayer.ca.2.bias', 'module.g3.gp.14.palayer.pa.0.weight', 'module.g3.gp.14.palayer.pa.0.bias', 'module.g3.gp.14.palayer.pa.2.weight', 'module.g3.gp.14.palayer.pa.2.bias', 'module.g3.gp.15.conv1.weight', 'module.g3.gp.15.conv1.bias', 'module.g3.gp.15.conv2.weight', 'module.g3.gp.15.conv2.bias', 'module.g3.gp.15.calayer.ca.0.weight', 'module.g3.gp.15.calayer.ca.0.bias', 'module.g3.gp.15.calayer.ca.2.weight', 'module.g3.gp.15.calayer.ca.2.bias', 'module.g3.gp.15.palayer.pa.0.weight', 'module.g3.gp.15.palayer.pa.0.bias', 'module.g3.gp.15.palayer.pa.2.weight', 'module.g3.gp.15.palayer.pa.2.bias', 'module.g3.gp.16.conv1.weight', 'module.g3.gp.16.conv1.bias', 'module.g3.gp.16.conv2.weight', 'module.g3.gp.16.conv2.bias', 'module.g3.gp.16.calayer.ca.0.weight', 'module.g3.gp.16.calayer.ca.0.bias', 'module.g3.gp.16.calayer.ca.2.weight', 'module.g3.gp.16.calayer.ca.2.bias', 'module.g3.gp.16.palayer.pa.0.weight', 'module.g3.gp.16.palayer.pa.0.bias', 'module.g3.gp.16.palayer.pa.2.weight', 'module.g3.gp.16.palayer.pa.2.bias', 'module.g3.gp.17.conv1.weight', 'module.g3.gp.17.conv1.bias', 'module.g3.gp.17.conv2.weight', 'module.g3.gp.17.conv2.bias', 'module.g3.gp.17.calayer.ca.0.weight', 'module.g3.gp.17.calayer.ca.0.bias', 'module.g3.gp.17.calayer.ca.2.weight', 'module.g3.gp.17.calayer.ca.2.bias', 'module.g3.gp.17.palayer.pa.0.weight', 'module.g3.gp.17.palayer.pa.0.bias', 'module.g3.gp.17.palayer.pa.2.weight', 'module.g3.gp.17.palayer.pa.2.bias', 'module.g3.gp.18.conv1.weight', 'module.g3.gp.18.conv1.bias', 'module.g3.gp.18.conv2.weight', 'module.g3.gp.18.conv2.bias', 'module.g3.gp.18.calayer.ca.0.weight', 'module.g3.gp.18.calayer.ca.0.bias', 'module.g3.gp.18.calayer.ca.2.weight', 'module.g3.gp.18.calayer.ca.2.bias', 'module.g3.gp.18.palayer.pa.0.weight', 'module.g3.gp.18.palayer.pa.0.bias', 'module.g3.gp.18.palayer.pa.2.weight', 'module.g3.gp.18.palayer.pa.2.bias', 'module.g3.gp.19.weight', 'module.g3.gp.19.bias', 'module.ca.1.weight', 'module.ca.1.bias', 'module.ca.3.weight', 'module.ca.3.bias', 'module.palayer.pa.0.weight', 'module.palayer.pa.0.bias', 'module.palayer.pa.2.weight', 'module.palayer.pa.2.bias', 'module.pre.0.weight', 'module.pre.0.bias', 'module.post.0.weight', 'module.post.0.bias', 'module.post.1.weight', 'module.post.1.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqzJ14GsEjFT",
        "outputId": "0ec5dee6-edac-4ac7-d9ad-aa37557a0831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w=np.transpose(pretrain['model']['module.post.1.weight'],[2,3,1,0])\n",
        "print(w.shape)\n",
        "b=pretrain['model']['module.post.1.bias'].numpy()\n",
        "print(b.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3, 64, 3])\n",
            "(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XiR9zyLBS6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e4c169-8c0a-46c3-9282-2d1c8cd77b50"
      },
      "source": [
        "w=np.transpose(pretrain['model']['module.palayer.pa.2.weight'],[2,3,1,0])\n",
        "print(w.shape)\n",
        "b=pretrain['model']['module.palayer.pa.2.bias'].numpy()\n",
        "print(b.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 8, 1])\n",
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zztG2VBGENU_"
      },
      "source": [
        "model.layers[-3].layers[0].layers[1].set_weights([w,b])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlvKH3STCCPy"
      },
      "source": [
        "model.layers[-1].layers[1].set_weights([w,b])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hpZc4VLwMbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bb6ece-c97b-4054-8dcc-60a4cb819820"
      },
      "source": [
        "\n",
        "w=np.transpose(pretrain['model']['module.g3.gp.19.weight'],[2,3,1,0])\n",
        "print(w.shape)\n",
        "b=pretrain['model']['module.g3.gp.19.bias'].numpy()\n",
        "print(b.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3, 64, 64])\n",
            "(64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlJntqFrwMd9"
      },
      "source": [
        "model.layers[2].layers[0].layers[-1].set_weights([w,b])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAZR_lk-A2T8"
      },
      "source": [
        "def set_weight(grp,block):\n",
        "  keyFind='module.g'+str(grp)+'.gp.'+str(block)+'.'\n",
        "  w=np.transpose(pretrain['model'][keyFind+'conv1.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'conv1.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[0].set_weights([w,b])\n",
        "\n",
        "  w=np.transpose(pretrain['model'][keyFind+'conv2.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'conv2.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[1].set_weights([w,b])\n",
        "\n",
        "  w=np.transpose(pretrain['model'][keyFind+'calayer.ca.0.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'calayer.ca.0.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[2].layers[0].layers[0].set_weights([w,b])\n",
        "\n",
        "  w=np.transpose(pretrain['model'][keyFind+'calayer.ca.2.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'calayer.ca.2.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[2].layers[0].layers[1].set_weights([w,b])\n",
        "\n",
        "  w=np.transpose(pretrain['model'][keyFind+'palayer.pa.0.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'palayer.pa.0.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[3].layers[0].layers[0].set_weights([w,b])\n",
        "\n",
        "\n",
        "  w=np.transpose(pretrain['model'][keyFind+'palayer.pa.2.weight'],[2,3,1,0])\n",
        "  b=pretrain['model'][keyFind+'palayer.pa.2.bias'].numpy()\n",
        "  model.layers[grp-1].layers[0].layers[block].layers[3].layers[0].layers[1].set_weights([w,b])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsmxUAanA2XE"
      },
      "source": [
        "for i in range(19):\n",
        "  set_weight(3,i)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDsB81auA2aM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3qCNQUxwMiP"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/nets/ffa/weights')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcOAS8Bx_7hC"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cc916e-350c-467e-bdf3-a1508fecdcb9"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 1\n",
        "\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/dataset/clear_images', hazy_img_path = './drive/MyDrive/dataset/haze',)\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = FFAnet(gps=3,blocks=8)\n",
        "net.load_weights('/content/drive/MyDrive/nets/ffa/weights')\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                #print(train_logits.shape)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')  \n",
        "        #net.save_weights('/content/drive/MyDrive/nets/ffa/weights')         # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37YWjqW-uWyN"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH"
      },
      "source": [
        "net.save('/content/drive/MyDrive/nets/ffa')\n",
        "\n",
        "net.save_weights('/content/drive/MyDrive/nets/ffa/weights')\n",
        "#model=net\n",
        "\n",
        "#model.model().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apmkwb-1udIK"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_gen(net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/Final_compare/HAZY/*.jpg')\n",
        "    #random.shuffle(test_img)\n",
        "    i=0;\n",
        "    for img in test_img:\n",
        "        print(img)\n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        img=tf.image.per_image_standardization(img)\n",
        "        print(i,end=\" \")\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze =net(img, training = True)\n",
        "        dehaze=tf.image.resize(dehaze, size = (413,550), antialias = True)\n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        directory = '/content/drive/MyDrive/Final_compare/ffa'\n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(\n",
        "    filename, \n",
        "\n",
        "im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sh6GG8rumQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794bc5bd-3b68-46e2-e38e-b19d298acca4"
      },
      "source": [
        "#new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/gca',compile=False)\n",
        "#new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/gca/trained_model',compile=False)\n",
        "#new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/test_custom_loss_net',compile=False)\n",
        "\n",
        "#net = FFAnet(gps=3,blocks=19)\n",
        "#net.load_weights('/content/drive/MyDrive/nets/ffa/weights')\n",
        "#evaluate_gen(new_model)\n",
        "evaluate_gen(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Final_compare/HAZY/0_outdoor_hazy.jpg\n",
            "0 /content/drive/MyDrive/Final_compare/HAZY/4_outdoor_hazy.jpg\n",
            "1 /content/drive/MyDrive/Final_compare/HAZY/2_outdoor_hazy.jpg\n",
            "2 /content/drive/MyDrive/Final_compare/HAZY/5_outdoor_hazy.jpg\n",
            "3 /content/drive/MyDrive/Final_compare/HAZY/3_outdoor_hazy.jpg\n",
            "4 /content/drive/MyDrive/Final_compare/HAZY/1_outdoor_hazy.jpg\n",
            "5 /content/drive/MyDrive/Final_compare/HAZY/6_outdoor_hazy.jpg\n",
            "6 /content/drive/MyDrive/Final_compare/HAZY/7_outdoor_hazy.jpg\n",
            "7 /content/drive/MyDrive/Final_compare/HAZY/8_outdoor_hazy.jpg\n",
            "8 /content/drive/MyDrive/Final_compare/HAZY/9_outdoor_hazy.jpg\n",
            "9 /content/drive/MyDrive/Final_compare/HAZY/10_outdoor_hazy.jpg\n",
            "10 /content/drive/MyDrive/Final_compare/HAZY/11_outdoor_hazy.jpg\n",
            "11 /content/drive/MyDrive/Final_compare/HAZY/12_outdoor_hazy.jpg\n",
            "12 /content/drive/MyDrive/Final_compare/HAZY/13_outdoor_hazy.jpg\n",
            "13 /content/drive/MyDrive/Final_compare/HAZY/14_outdoor_hazy.jpg\n",
            "14 /content/drive/MyDrive/Final_compare/HAZY/15_outdoor_hazy.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinhPC_5OSPB"
      },
      "source": [
        "## Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iylDejI5qxZH"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size,padding=(kernel_size//2), bias=bias)\n",
        "    \n",
        "class PALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(PALayer, self).__init__()\n",
        "        self.pa = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(CALayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.ca = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1=conv(dim, dim, kernel_size, bias=True)\n",
        "        self.act1=nn.ReLU(inplace=True)\n",
        "        self.conv2=conv(dim,dim,kernel_size,bias=True)\n",
        "        self.calayer=CALayer(dim)\n",
        "        self.palayer=PALayer(dim)\n",
        "    def forward(self, x):\n",
        "        res=self.act1(self.conv1(x))\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "class Group(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group, self).__init__()\n",
        "        modules = [ Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(conv(dim, dim, kernel_size))\n",
        "        self.gp = nn.Sequential(*modules)\n",
        "    def forward(self, x):\n",
        "        res = self.gp(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class FFA(nn.Module):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFA, self).__init__()\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [conv(3, self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.ca=nn.Sequential(*[\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "            ])\n",
        "        self.palayer=PALayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = nn.Sequential(*pre_process)\n",
        "        self.post = nn.Sequential(*post_precess)\n",
        "\n",
        "    def forward(self, x1):\n",
        "        x = self.pre(x1)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "        #return res3\n",
        "        w=torch.cat([res1,res2,res3],dim=1)\n",
        "        w=self.ca(w)\n",
        "        #return w\n",
        "        w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]\n",
        "        #print(h.shape)\n",
        "        #return h\n",
        "        \n",
        "        out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3\n",
        "        \n",
        "        #return out\n",
        "        out=self.palayer(out)\n",
        "        #return out\n",
        "        x=self.post(out)\n",
        "        return x + x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awsfQhl5q2rw"
      },
      "source": [
        "from torchsummary import summary\n",
        "net=FFA(gps=3,blocks=19)\n",
        "#if torch.cuda.is_available():\n",
        "#net.cuda(device='cpu')\n",
        "#print(summary(net, (3, 412, 548)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OWIHI4esYhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b8fa02-d47a-4eef-debb-fbb08c5c5dd0"
      },
      "source": [
        "!git clone https://github.com/gzuidhof/nn-transfer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nn-transfer'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Total 190 (delta 0), reused 0 (delta 0), pack-reused 190\u001b[K\n",
            "Receiving objects: 100% (190/190), 35.62 KiB | 1.42 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PGuWXj547Jr",
        "outputId": "3acaf9f2-39e0-438d-a88d-bb4cecd2ec00"
      },
      "source": [
        "pip install ./nn-transfer/."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./nn-transfer\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nn-transfer==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from nn-transfer==0.1.0) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nn-transfer==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->nn-transfer==0.1.0) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->nn-transfer==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->nn-transfer==0.1.0) (1.5.2)\n",
            "Building wheels for collected packages: nn-transfer\n",
            "  Building wheel for nn-transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nn-transfer: filename=nn_transfer-0.1.0-cp37-none-any.whl size=4370 sha256=bbc87a106758507340c1af338aaf074bafd2ea0e1d24526e17974d6dd61cfa39\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/e8/e3/8d4084052a5c54875f1ba69fefcc39f3568d088c0fe3e1ed2e\n",
            "Successfully built nn-transfer\n",
            "Installing collected packages: nn-transfer\n",
            "Successfully installed nn-transfer-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WO_DpyF48ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84af951-d5ad-4d50-b94f-ba292605c64d"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_outdoor_gen.jpg   1_outdoor_gen.jpg   2_outdoor_gen.jpg   3_outdoor_gen.jpg\n",
            "10_outdoor_gen.jpg  20_outdoor_gen.jpg  30_outdoor_gen.jpg  40_outdoor_gen.jpg\n",
            "11_outdoor_gen.jpg  21_outdoor_gen.jpg  31_outdoor_gen.jpg  41_outdoor_gen.jpg\n",
            "12_outdoor_gen.jpg  22_outdoor_gen.jpg  32_outdoor_gen.jpg  4_outdoor_gen.jpg\n",
            "13_outdoor_gen.jpg  23_outdoor_gen.jpg  33_outdoor_gen.jpg  5_outdoor_gen.jpg\n",
            "14_outdoor_gen.jpg  24_outdoor_gen.jpg  34_outdoor_gen.jpg  6_outdoor_gen.jpg\n",
            "15_outdoor_gen.jpg  25_outdoor_gen.jpg  35_outdoor_gen.jpg  7_outdoor_gen.jpg\n",
            "16_outdoor_gen.jpg  26_outdoor_gen.jpg  36_outdoor_gen.jpg  8_outdoor_gen.jpg\n",
            "17_outdoor_gen.jpg  27_outdoor_gen.jpg  37_outdoor_gen.jpg  9_outdoor_gen.jpg\n",
            "18_outdoor_gen.jpg  28_outdoor_gen.jpg  38_outdoor_gen.jpg  \u001b[0m\u001b[01;34mnn-transfer\u001b[0m/\n",
            "19_outdoor_gen.jpg  29_outdoor_gen.jpg  39_outdoor_gen.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yuzEliY9Qaz"
      },
      "source": [
        "a=np.random.randn(3,3,64,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR-fdDNs9Vbm",
        "outputId": "a763633f-12e2-43cf-9dca-5fdb4ed85cc8"
      },
      "source": [
        "np.transpose(a,[3,2,0,1]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 64, 3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24dEvFyL-56o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}