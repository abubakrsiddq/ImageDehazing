{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "modelSub.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "9bb71057-bbc3-443f-ab36-d5d2824ad634"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "import cv2\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    #print(\"input image quality\",display_list)#niqe(cv2.imread(display_list[1])))\n",
        "    #print(\"input image quality\",niqe(cv2.imread(display_list[2])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOzDIDpqjZBn"
      },
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return tf.keras.layers.Conv2D(out_channels, kernel_size,padding='same', use_bias=bias)\n",
        "    \n",
        "class PixAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(PixAtLayer, self).__init__()\n",
        "        self.pa = tf.keras.Sequential(\n",
        "                tf.keras.layers.Conv2D(channel // 8, 1, padding='valid',activation='relu'),\n",
        "                \n",
        "                tf.keras.layers.Conv2D( 1, 1,activation='sigmoid')        \n",
        "        )\n",
        "    def call(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "class ChanAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(ChanAtLayer, self).__init__()\n",
        "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.ca = tf.keras.Sequential(\n",
        "                 tf.keras.layers.Conv2D(channel // 8, 1,activation='relu'),\n",
        "                \n",
        "                 tf.keras.layers.Conv2D(channel, 1, activation='sigmoid'))\n",
        "\n",
        "    def call(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "class Block_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block_layer, self).__init__()\n",
        "        self.conv1=conv(dim,dim, kernel_size, bias=True,activation='relu')\n",
        "        \n",
        "        self.conv2=conv(dim,dim, kernel_size, bias=True)\n",
        "        self.calayer=ChanAtLayer(dim)\n",
        "        self.palayer=PixAtLayer(dim)\n",
        "    def call(self, x):\n",
        "        res=self.conv1(x)\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "\n",
        "class Group_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group_layer, self).__init__()\n",
        "        modules = [ Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(tf.keras.layers.Conv2D(dim, kernel_size))\n",
        "        self.gp = tf.keras.Sequential(*modules)\n",
        "    def call(self, x):\n",
        "        res = self.gp(x)\n",
        "        res += x\n",
        "        return res\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCX-CqzehI3"
      },
      "source": [
        "class FFAnet(tf.keras.Model):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFAnet, self).__init__()\n",
        "        # define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [tf.keras.layers.Conv2D(self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "\n",
        "        self.ca=nn.Sequential(*[\n",
        "            tf.keras.layers.GlobalAveragePooling2D,\n",
        "            tf.keras.layers.Conv2D(self.dim//16,1,padding='valid'),\n",
        "            \n",
        "            tf.keras.layers.Conv2D(self.dim*self.gps, 1, padding='valid', bias=True,activation='sigmoid')\n",
        "            \n",
        "            ])\n",
        "        self.palayer=PixAtLayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = tf.keras.Sequential(*pre_process)\n",
        "        self.post = tf.keras.Sequential(*post_precess)\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        # forward pass: block 1 \n",
        "        x = self.pre(x1)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "        return res3\n",
        "        #w=self.ca(torch.cat([res1,res2,res3],dim=1))\n",
        "        #w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]\n",
        "        #out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3\n",
        "        #out=self.palayer(out)\n",
        "        x=self.post(out)\n",
        "        #return x + x1\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "htg4Y_MW0Jfo",
        "outputId": "ffdb5bce-677e-4ce4-c2fe-972958a0d6f2"
      },
      "source": [
        "sub =FFAnet(gps=3,blocks=19)\n",
        "sub.model().summary()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-50e4f9b52485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mFFAnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5e18456a56ed>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gps, blocks, conv)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpre_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGroup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGroup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGroup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d72b3844dacf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, conv, dim, kernel_size, blocks)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroup_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d72b3844dacf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroup_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Block' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = ModelSubClassing()\n",
        "\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                #print(train_logits.shape)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "sbnB0QNYKnKs",
        "outputId": "3cc91f0e-4874-48a1-9aef-879b642bd5e5"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b0302f0e0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-814522eb9084>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdc74a1-e20a-440a-9799-36088c824204"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 412, 548, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 412, 548, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 3,523\n",
            "Trainable params: 3,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinhPC_5OSPB"
      },
      "source": [
        "## Learn"
      ]
    }
  ]
}